"""
title: Multi-Language Toxicity Filter
author: open-webui
date: 2024-05-30
version: 2.1
license: MIT
description: Toxicity filter for both English and Russian
requirements: detoxify transformers torch
"""

from typing import List, Optional
from pydantic import BaseModel
import os
import re

class Pipeline:
    class Valves(BaseModel):
        pipelines: List[str] = ["*"]
        priority: int = 0
        toxicity_threshold: float = 0.5
        language_detection: bool = True

    def __init__(self):
        self.type = "filter"
        self.name = "Multi-Language Toxicity Filter"
        self.valves = self.Valves(pipelines=["*"])
        
        self.detoxify_model = None
        self.russian_model = None
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ (–∫–∞–∫ fallback)
        self.russian_toxic_keywords = [
            "–º—É–¥–∞–∫", "–¥–æ–ª–±–æ—ë–±", "—É—Ä–æ–¥", "–∏–¥–∏–æ—Ç", "–¥–µ–±–∏–ª", "–∫—Ä–µ—Ç–∏–Ω",
            "—Å–æ—Å–∏", "–æ—Ç—ä–µ–±–∏—Å—å", "–ø–æ—à—ë–ª –Ω–∞—Ö—É–π", "–ø–∏–∑–¥–µ—Ü", "–±–ª—è–¥—å",
            "—Ö—É–π", "–ø–∏–∑–¥–∞", "–µ–±–∞—Ç—å", "–≥–æ–Ω–¥–æ–Ω", "–ø–∏–¥–æ—Ä", "–ø–µ–¥–∏–∫"
        ]

    async def on_startup(self):
        print(f"on_startup:{__name__}")
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å Detoxify –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ
        try:
            from detoxify import Detoxify
            self.detoxify_model = Detoxify("original")
            print("‚úÖ Detoxify –∑–∞–≥—Ä—É–∂–µ–Ω (–¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ)")
        except ImportError:
            print("‚ö†Ô∏è Detoxify –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: pip install detoxify")
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä—É—Å—Å–∫—É—é –º–æ–¥–µ–ª—å
        try:
            from transformers import pipeline
            self.russian_model = pipeline(
                "text-classification",
                model="cointegrated/rubert-tiny-toxicity"
            )
            print("‚úÖ –†—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except ImportError:
            print("‚ö†Ô∏è transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: pip install transformers torch")

    def detect_language(self, text: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º"""
        # –°—á–∏—Ç–∞–µ–º –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
        cyrillic_count = len(re.findall(r'[–∞-—è–ê-–Ø—ë–Å]', text))
        latin_count = len(re.findall(r'[a-zA-Z]', text))
        
        if cyrillic_count > latin_count:
            return "ru"
        else:
            return "en"

    def check_russian_keywords(self, text: str) -> float:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (fallback)"""
        text_lower = text.lower()
        matches = sum(1 for word in self.russian_toxic_keywords 
                     if word in text_lower)
        
        if matches > 0:
            return min(0.5 + (matches * 0.1), 1.0)
        return 0.0

    async def inlet(self, body: dict, user: Optional[dict] = None) -> dict:
        if "messages" not in body or len(body["messages"]) == 0:
            return body
        
        last_message = body["messages"][-1]
        if last_message["role"] != "user":
            return body
        
        user_message = last_message["content"]
        print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞: {user_message[:50]}...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫
        language = self.detect_language(user_message)
        print(f"üåê –û–ø—Ä–µ–¥–µ–ª–µ–Ω —è–∑—ã–∫: {language}")
        
        toxicity_score = 0.0
        
        if language == "en" and self.detoxify_model:
            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º Detoxify
            result = self.detoxify_model.predict(user_message)
            toxicity_score = result["toxicity"]
            print(f"üá¨üáß Detoxify score: {toxicity_score:.3f}")
            
        elif language == "ru":
            if self.russian_model:
                # –†—É—Å—Å–∫–∏–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –º–æ–¥–µ–ª—å
                result = self.russian_model(user_message)[0]
                label = result["label"]
                toxicity_score = result["score"] if label == "toxic" else 1 - result["score"]
                print(f"üá∑üá∫ Russian model: {label} ({toxicity_score:.3f})")
            else:
                # Fallback - –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                toxicity_score = self.check_russian_keywords(user_message)
                print(f"üá∑üá∫ Keywords check: {toxicity_score:.3f}")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
        if toxicity_score > self.valves.toxicity_threshold:
            print(f"üö´ –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–µ–Ω–∞: {toxicity_score:.3f} > {self.valves.toxicity_threshold}")
            from fastapi import HTTPException
            raise HTTPException(
                status_code=400,
                detail={
                    "error": "–¢–æ–∫—Å–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ",
                    "score": toxicity_score,
                    "language": language,
                    "threshold": self.valves.toxicity_threshold
                }
            )
        
        print(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ: {toxicity_score:.3f}")
        return body